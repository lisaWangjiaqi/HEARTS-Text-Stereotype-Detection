


import sys
import torch
import transformers
from datasets import load_dataset

print("Python version:", sys.version)
print("PyTorch version:", torch.__version__)
print("Transformers version:", transformers.__version__)

# Load EMGSD from Hugging Face
ds = load_dataset("holistic-ai/EMGSD")
print(ds)

# Inspect one training example
example = ds["train"][0]
for k, v in example.items():
    print(f"{k}: {v}")






from collections import Counter


# Count how many distinct labels we have in EMGSD
label_list = sorted(list(set(ds["train"]["label"])))
print("Number of unique labels:", len(label_list))
print("Label examples:", label_list[:10])

# Map string labels -> integer ids for training
label2id = {lab: i for i, lab in enumerate(label_list)}
id2label = {i: lab for lab, i in label2id.items()}
print("Example mapping:", list(label2id.items())[:5])

MODEL_NAME = "albert-base-v2"
NUM_LABELS = len(label_list)
BATCH_SIZE = 16
LEARNING_RATE = 2e-5
NUM_EPOCHS = 3

print("MODEL_NAME:", MODEL_NAME)
print("NUM_LABELS:", NUM_LABELS)
print("BATCH_SIZE:", BATCH_SIZE)
print("LEARNING_RATE:", LEARNING_RATE)
print("NUM_EPOCHS:", NUM_EPOCHS)






get_ipython().getoutput("python ../src/train_emgsd_albert.py \")
    --model_name albert-base-v2 \
    --output_dir ../results/emgsd_baseline \
    --batch_size 16 \
    --learning_rate 2e-5 \
    --num_epochs 3






import json
from pathlib import Path

metrics_path = Path("../results/emgsd_baseline/metrics.json")

if metrics_path.exists():
    with open(metrics_path) as f:
        metrics = json.load(f)
    print("Loaded metrics:", metrics)
else:
    print("metrics.json not found yet. Run the training cell above first.")




