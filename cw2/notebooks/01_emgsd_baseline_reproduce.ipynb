{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761c9770",
   "metadata": {},
   "source": [
    "# 1. Environment & Data Loading\n",
    "\n",
    "This notebook reproduces the EMGSD baseline (ALBERT) from the HEARTS repository.\n",
    "We first check the environment and load the EMGSD dataset from Hugging Face.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36984aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sys\u001b[38;5;241m.\u001b[39mversion)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "# Load EMGSD from Hugging Face\n",
    "ds = load_dataset(\"holistic-ai/EMGSD\")\n",
    "print(ds)\n",
    "\n",
    "# Inspect one training example\n",
    "example = ds[\"train\"][0]\n",
    "for k, v in example.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e57970",
   "metadata": {},
   "source": [
    "# 2. Model & Training Configuration\n",
    "\n",
    "We specify the model backbone (ALBERT), the number of labels, and the key training hyperparameters.\n",
    "These values are chosen to be consistent with the original HEARTS repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ec8020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 13\n",
      "Label examples: ['neutral_gender', 'neutral_lgbtq+', 'neutral_nationality', 'neutral_profession', 'neutral_race', 'neutral_religion', 'stereotype_gender', 'stereotype_lgbtq+', 'stereotype_nationality', 'stereotype_profession']\n",
      "Example mapping: [('neutral_gender', 0), ('neutral_lgbtq+', 1), ('neutral_nationality', 2), ('neutral_profession', 3), ('neutral_race', 4)]\n",
      "MODEL_NAME: albert-base-v2\n",
      "NUM_LABELS: 13\n",
      "BATCH_SIZE: 16\n",
      "LEARNING_RATE: 2e-05\n",
      "NUM_EPOCHS: 3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Count how many distinct labels we have in EMGSD\n",
    "label_list = sorted(list(set(ds[\"train\"][\"label\"])))\n",
    "print(\"Number of unique labels:\", len(label_list))\n",
    "print(\"Label examples:\", label_list[:10])\n",
    "\n",
    "# Map string labels -> integer ids for training\n",
    "label2id = {lab: i for i, lab in enumerate(label_list)}\n",
    "id2label = {i: lab for lab, i in label2id.items()}\n",
    "print(\"Example mapping:\", list(label2id.items())[:5])\n",
    "\n",
    "MODEL_NAME = \"albert-base-v2\"\n",
    "NUM_LABELS = len(label_list)\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "print(\"MODEL_NAME:\", MODEL_NAME)\n",
    "print(\"NUM_LABELS:\", NUM_LABELS)\n",
    "print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "print(\"LEARNING_RATE:\", LEARNING_RATE)\n",
    "print(\"NUM_EPOCHS:\", NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f30b2",
   "metadata": {},
   "source": [
    "# 3. Training Script Call\n",
    "\n",
    "We call a separate training script (`cw2/src/train_emgsd_albert.py`) so that\n",
    "the whole baseline can be reproduced from the command line and from this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../src/train_emgsd_albert.py \\\n",
    "    --model_name albert-base-v2 \\\n",
    "    --output_dir ../results/emgsd_baseline \\\n",
    "    --batch_size 16 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_epochs 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac220f7",
   "metadata": {},
   "source": [
    "# 4. Evaluation & Comparison\n",
    "\n",
    "After training, we load the saved metrics and compare our EMGSD performance\n",
    "against the values reported in the HEARTS paper (Â±5% tolerance on macro-F1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0eeb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "metrics_path = Path(\"../results/emgsd_baseline/metrics.json\")\n",
    "\n",
    "if metrics_path.exists():\n",
    "    with open(metrics_path) as f:\n",
    "        metrics = json.load(f)\n",
    "    print(\"Loaded metrics:\", metrics)\n",
    "else:\n",
    "    print(\"metrics.json not found yet. Run the training cell above first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45d1be-0030-4752-aba0-c98be4b162c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
